{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Model details\n",
    "\n",
    "\n",
    "The probability distributions\n",
    "\n",
    "- $P(Y_{i}|Y_{i-1})$ are called transition probabilities; \n",
    "- $P(Y_{1}|Y_{0} = {\\tt start})$ are the initial probabilities\n",
    "- $P(Y_{N+1}={\\tt stop} |Y_{N})$ the final probabilities\n",
    "\n",
    "A first order HMM model has the following independence assumptions over the joint distribution $P(X=x,Y=y)$:\n",
    "\n",
    "- $\\textbf{Independence of previous states.}$: The probability of\n",
    "    being in a given state at position $i$ only depends on\n",
    "    the state of the previous position $i-1$. Formally:\n",
    "    \n",
    "    \\begin{equation*}\n",
    "    P (Y_i = y_i | Y_{i-1} = y_{i-1}, Y_{i-2} = y_{i-2}, \\ldots, Y_1 = y_1) = P (Y_i = y_i | Y_{i-1} = y_{i-1})\n",
    "    \\end{equation*} \n",
    "    \n",
    "    defining a first order Markov chain\n",
    "\n",
    "\n",
    "- $\\textbf{Homogeneous transition.}$: The probability of\n",
    "    making a transition from state $c_l$ to state $c_k$ is independent of\n",
    "    the particular position in the sequence. That is, for all $i,t \\in \\{1,\\ldots,N\\}$,\n",
    "    \n",
    "     \\begin{equation*}\n",
    "    P (Y_i = c_k | Y_{i-1} = c_l) =  P (Y_{t} = c_k | Y_{t-1} = c_l)\n",
    "     \\end{equation*}\n",
    "\n",
    "\n",
    "- $\\textbf{Observation independence.}$  The probability of\n",
    "    observing $X_i = x_i$ at position $i$ is fully determined by the state $Y_i$\n",
    "    at that position. Formally, \n",
    "    \n",
    "     \\begin{equation*}\n",
    "     P (X_i = x_i | Y_1=y_1, \\ldots, Y_i=y_i, \\ldots, Y_N=y_N) = P(X_i = x_i | Y_i = y_i)\n",
    "      \\end{equation*}\n",
    "     \n",
    "     This probability is independent of the\n",
    "    particular position so, for every $i$ and $t$, we can write:  \n",
    "    \n",
    "     \\begin{equation*}\n",
    "    P(X_i = w_j | Y_i = c_k) = P(X_{t} = w_j | Y_{t} = c_k)\n",
    "     \\end{equation*}\n",
    "\n",
    "These conditional independence assumptions are crucial to allow\n",
    "efficient inference, as it will be described.\n",
    "\n",
    "\n",
    "### Table summary\n",
    "\n",
    " The distributions that define the HMM model are summarized in the following table\n",
    "\n",
    "<img src=\"../images_for_notebooks/day_2/Hmm_table.png\" style=\"max-width:100%; width: 75%\">\n",
    "\n",
    "### Joint distribution $P(X,Y)$\n",
    "\n",
    "The joint probability of a first order HMM can be written as follows:\n",
    "$$\n",
    "P(X_1=x_1,\\ldots,X_N=x_N,Y_1=y_1,\\ldots,Y_N=y_N)= \n",
    "P_{\\mathrm{init}}(y_1|\\text{ start}) \n",
    "\\cdot\n",
    "\\left(\n",
    "\\prod_{i=1}^{N-1} P_{\\mathrm{trans}}(y_{i+1}|y_i)\n",
    "\\right)\n",
    "\\times\n",
    "P_{\\mathrm{final}}(\\text{ stop}|y_N)\n",
    "\\cdot \n",
    "\\prod_{i=1}^{N} P_{\\mathrm{emiss}}(x_i|y_i)\n",
    "$$\n",
    "\n",
    "#### Example: computing the probability of a pair $(x,y)$\n",
    "the probability of an HMM for the first training instance of Example 2.1, which is \n",
    "\n",
    "$$\n",
    "(x,y) = ([\\text{walk}, \\text{walk}, \\text{shop}, \\text{clean}],  [\\text{rainy}, \\text{sunny},\\text{ sunny}, \\text{sunny}])\n",
    "$$\n",
    "can be computed as\n",
    "\n",
    "$$\n",
    "P(X_1=x_1,\\ldots,X_4=x_4,Y_1=y_1,\\ldots,Y_4=y_4)= \n",
    "P_{\\text{init}}(\\text{rainy}|\\text{ start}) \n",
    "\\cdot\n",
    "P_{\\mathrm{trans}}(\\text{ sunny}|\\text{ rainy}) \n",
    "\\cdot\n",
    "P_{\\mathrm{trans}}(\\text{ sunny}|\\text{ sunny}) \n",
    "\\cdot\n",
    "P_{\\mathrm{trans}}(\\text{ sunny}|\\text{ sunny}) \n",
    "\\cdot\n",
    "P_{\\mathrm{final}}(\\text{ stop}|\\text{ sunny}) \n",
    "\\cdot\n",
    "P_{\\mathrm{emiss}}(\\text{ walk}|\\text{ rainy}) \n",
    "\\cdot\n",
    "P_{\\mathrm{emiss}}(\\text{ walk}|\\text{ sunny}) \n",
    "\\cdot\n",
    "P_{\\mathrm{emiss}}(\\text{ shop}|\\text{ sunny})\n",
    "\\cdot\n",
    "P_{\\mathrm{emiss}}(\\text{ clean}|\\text{ sunny}).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HMM Maximum Likelihood Training\n",
    "\n",
    "We have seen how to compute the probability of a pair $(x,y)$ given the probabilities $P_{\\text{init}}, P_{\\text{trans}},P_{\\text{final}},P_{\\text{emiss}}$.\n",
    "\n",
    "Now we will study how to find the parameters that define $P_{\\text{init}}, P_{\\text{trans}},P_{\\text{final}},P_{\\text{emiss}}$. We will refer to the set of parameters as $\\theta$.\n",
    "\n",
    "Given a dataset $\\mathcal{D}_L$, we will try to find the parameters $\\theta$ that maximize the log likelihood function:\n",
    "\n",
    "$$\n",
    "\\log \\prod_{m=1}^M P_{\\theta} (X=x^m,Y=y^m) =  \\sum_{m=1}^M  \\log P_{\\theta} (X=x^m,Y=y^m)\n",
    "$$\n",
    "\n",
    "where the joint distribution $P_{\\theta} (X=x^m,Y=y^m)$ is given by the formula \n",
    "\n",
    "$$\n",
    "P(X_1=x_1,\\ldots,X_N=x_N,Y_1=y_1,\\ldots,Y_N=y_N)= \n",
    "P_{\\mathrm{init}}(y_1|\\text{ start}) \n",
    "\\cdot\n",
    "\\left(\n",
    "\\prod_{i=1}^{N-1} P_{\\mathrm{trans}}(y_{i+1}|y_i)\n",
    "\\right)\n",
    "\\times\n",
    "P_{\\mathrm{final}}(\\text{ stop}|y_N)\n",
    "\\cdot \n",
    "\\prod_{i=1}^{N} P_{\\mathrm{emiss}}(x_i|y_i)\n",
    "$$\n",
    "\n",
    "In some applications  (such as speech recognition) \n",
    "the observation variables are continuous, hence the emission distributions are real-valued ( e.g. mixtures of Gaussians). In our case, both the state set and the observation set are discrete (and finite), therefore we use\n",
    "multinomial distributions for the emission and \n",
    "transition probabilities. \n",
    "\n",
    "Multinomial distributions are attractive for several reasons: first of\n",
    "all, they are easy to implement; secondly, the maximum likelihood estimation of the parameters has a simple closed form. The parameters are just normalized counts of events that occur in the corpus.\n",
    "\n",
    " Let us define the following\n",
    "quantities, called sufficient statistics, that represent the counts of\n",
    "each event in the corpus:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initial counts:\n",
    "$$C_{\\text{init}}(c_k) = \\sum_{m=1}^M\n",
    "\\mathbb{1} (y^m_1 = c_k)\n",
    "$$\n",
    "\n",
    "- Transition counts: $$\n",
    "C_{\\text{trans}}(c_k,c_l) =\n",
    "\\sum_{m=1}^M  \\sum_{i = 2}^{N}\n",
    "\\mathbb{1} (y^m_i = c_k \\wedge y^m_{i-1} = c_l)\n",
    "$$\n",
    "\n",
    "- Final counts:\n",
    "$$\n",
    "C_{\\text{final}}(c_k) = \\sum_{m=1}^M\n",
    "\\mathbb{1} (y^m_N = c_k)\n",
    "$$\n",
    "\n",
    "- Emission counts:\n",
    "$$\n",
    "C_{\\text{emiss}}(w_j,c_k) = \\sum_{m=1}^M\n",
    "\\sum_{i = 1}^{N}\n",
    "\\mathbb{1} (x^m_i = w_j \\wedge y^m_i = c_k)\n",
    "$$\n",
    "\n",
    "Here $y^m_i$,  the underscript denotes the state index position for a given sequence, and the superscript denotes the sequence index in the dataset, and the same applies for the observations.\n",
    "Note that $\\mathbb{1}$ is an indicator function that has the value 1 when the\n",
    "particular event happens, and zero otherwise. In other words, the previous\n",
    "equations go through the training corpus and count how\n",
    "often each event occurs. For example trainsition counts, counts how many times $c_k$ follows state $c_l$. Therefore, $C_{\\text{trans}}(\\text{ sunny},\\text{ rainy})$ contains the number of times that a sunny day followed a rainy day.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sanity check for the HMM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Initial counts must sum to the number of sentences  $$ \\sum_{k=1}^K C_{\\text{init}}(c_k) = M$$\n",
    "\n",
    "- Transition counts and Final Counts should sum to the number of tokens: $$\\sum_{k,l=1}^K C_{\\text{trans}}(c_k,c_l)  + \\sum_{k=1}^K C_{\\text{final}}(c_k) = M \\cdot N$$\n",
    "\n",
    "- Emission counts must sum to the number of tokens\n",
    "$$\n",
    "\\sum_{j=1}^J \\sum_{k=1}^K C_{\\text{emiss}}(w_j,c_k) = M \\cdot N \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an HMM: Finding the parameters of the distributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following formulas specify how to find the parameters of the HMM:\n",
    "\n",
    "$$\n",
    "P_{\\text{init}}(c_k \\,\\vert\\, \\text{start}) = \\frac{C_{\\text{init}}(c_k)}{ \\sum_{k=1}^K\n",
    "C_{\\text{init}} (c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{final}}(\\text{stop} \\,\\vert\\, c_l) = \\frac{C_{\\text{final}}(c_l) }\n",
    "{\\sum_{k=1}^K C_{\\text{trans}}(c_k,c_l) + C_{\\text{final}}(c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{trans}}( c_k \\,\\vert\\, c_l) = \\frac{C_{\\text{trans}}(c_k, c_l) }\n",
    "{\\sum_{p=1}^K C_{\\text{trans}}(c_p,c_l) + C_{\\text{final}}(c_l)}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P_{\\text{emiss}} (w_j \\,\\vert\\, c_k) = \\frac{C_{\\text{emiss}} (w_j, c_k) }{\\sum_{q=1}^J C_{\\text{emiss}}(w_q,c_k)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2.2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The provided function train supervised from the hmm.py file implements the above parameter estimates.  Run this function given the simple dataset above and look at the estimated probabilities. Are they correct? \n",
    "\n",
    "You can also check the variables ending in  counts instead of  probs to see the raw counts (for example, typing ``hmm.initial_counts`` will show you the raw counts of initial states). How are the counts related to the probabilities?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "# We will this append to ensure we can import lxmls toolking\n",
    "sys.path.append('../../lxmls-toolkit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import lxmls.sequences.hmm as hmmc\n",
    "import lxmls.readers.simple_sequence as ssr\n",
    "\n",
    "# Load data\n",
    "simple = ssr.SimpleSequence()\n",
    "\n",
    "# instanciate HMM model using the loaded data\n",
    "hmm = hmmc.HMM(simple.x_dict, simple.y_dict)\n",
    "\n",
    "# Train the HMM\n",
    "hmm.train_supervised(simple.train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Counts:\n",
      "[ 2.  1.] \n",
      "\n",
      "Transition Counts:\n",
      "[[ 2.  0.]\n",
      " [ 2.  5.]] \n",
      "\n",
      "Final Counts:\n",
      "[ 0.  3.] \n",
      "\n",
      "Emission Counts\n",
      "[[ 3.  2.]\n",
      " [ 1.  3.]\n",
      " [ 0.  3.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print \"Initial Counts:\\n\", hmm.initial_counts ,\"\\n\"\n",
    "print \"Transition Counts:\\n\", hmm.transition_counts ,\"\\n\"\n",
    "print \"Final Counts:\\n\", hmm.final_counts ,\"\\n\"\n",
    "print \"Emission Counts\\n\", hmm.emission_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial_probs \n",
      "[ 0.66666667  0.33333333]\n",
      "\n",
      "transition_probs\n",
      "[[ 0.5    0.   ]\n",
      " [ 0.5    0.625]]\n",
      "\n",
      "final_probs\n",
      "[ 0.     0.375]\n",
      "\n",
      "emission_probs\n",
      "[[ 0.75   0.25 ]\n",
      " [ 0.25   0.375]\n",
      " [ 0.     0.375]\n",
      " [ 0.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print \"initial_probs \"\n",
    "print hmm.initial_counts / np.sum(hmm.initial_counts)\n",
    "\n",
    "print \"\\ntransition_probs\"\n",
    "print hmm.transition_counts / (np.sum(hmm.transition_counts, 0) + hmm.final_counts)\n",
    "\n",
    "print \"\\nfinal_probs\"\n",
    "print hmm.final_counts / (np.sum(hmm.transition_counts, 0) + hmm.final_counts)\n",
    "\n",
    "print \"\\nemission_probs\"\n",
    "print hmm.emission_counts / np.sum(hmm.emission_counts, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OBSERVATION:\n",
    "\n",
    "**If we stack trainsition and final counts and normalize them we get\n",
    "a proper conditional probability distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transitions_with_final_counts = np.vstack((hmm.transition_counts,\n",
    "                                           hmm.final_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.,  0.],\n",
       "       [ 2.,  5.],\n",
       "       [ 0.,  3.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions_with_final_counts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.5  ,  0.   ],\n",
       "       [ 0.5  ,  0.625],\n",
       "       [ 0.   ,  0.375]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transitions_with_final_counts/ np.sum(transitions_with_final_counts,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Probabilities:\n",
      "[ 0.66666667  0.33333333] \n",
      "\n",
      "Transition 'Probabilities':\n",
      "[[ 0.5    0.   ]\n",
      " [ 0.5    0.625]] \n",
      "\n",
      "Final 'Probabilities':\n",
      "[ 0.     0.375] \n",
      "\n",
      "Emission Probabilities\n",
      "[[ 0.75   0.25 ]\n",
      " [ 0.25   0.375]\n",
      " [ 0.     0.375]\n",
      " [ 0.     0.   ]]\n"
     ]
    }
   ],
   "source": [
    "print \"Initial Probabilities:\\n\", hmm.initial_probs ,\"\\n\"\n",
    "print \"Transition 'Probabilities':\\n\", hmm.transition_probs ,\"\\n\"\n",
    "print \"Final 'Probabilities':\\n\", hmm.final_probs ,\"\\n\"\n",
    "print \"Emission Probabilities\\n\", hmm.emission_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
