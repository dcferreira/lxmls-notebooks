{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured Perceptron\n",
    "\n",
    "The structured perceptron, namely its averaged version, is a very simple\n",
    "algorithm that relies on Viterbi decoding and very simple additive\n",
    "updates. In practice this algorithm is very easy to implement and\n",
    "behaves remarkably well in a variety of problems. These two\n",
    "characteristics make the structured perceptron algorithm a natural\n",
    "first choice to try and test a new problem or a new feature set. \n",
    "\n",
    "<img src=\"../images_for_notebooks/day_3/structured_perceptron.png\">\n",
    "\n",
    "\n",
    "\n",
    "There are only two differences, which mimic the ones already seen for the comparison between CRFs \n",
    "and multi-class ME models:\n",
    "\n",
    "- Instead of explicitly enumerating all possible output  configurations (exponentially many of them) to compute \n",
    " $$\\widehat{y} := \\text{argmax}_{y'\\in\\mathcal{Y}} W \\cdot F(x^m,y')$$, \n",
    "it finds the best sequence through the Viterbi algorithm. \n",
    "\n",
    "\n",
    "- Instead of updating the features for the entire $\\widehat{y}$, \n",
    "it updates only the node and edge features at the positions where the\n",
    "  labels are different i.e., where mistakes are made.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "# We will this append to ensure we can import lxmls toolking\n",
    "sys.path.append('../../lxmls-toolkit')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.3 - Algorithm implementation\n",
    "\n",
    "**Implement the structured perceptron algorithm.**\n",
    "\n",
    "**To do this, edit file ```sequences/structured_perceptron.py``` and implement the function ```.perceptron_updates```**\n",
    "\n",
    "         \n",
    "This function should apply one round of the perceptron algorithm, updating the weights for a given sequence, and returning the number of predicted labels (which equals the sequence length) and the number of mistaken labels.\n",
    "\n",
    "Hint: You can try to adapt the function\n",
    "\n",
    "    def gradient_update(self, sequence, eta):\n",
    "\n",
    "\n",
    "You will need to replace the computation of posterior marginals by the Viterbi algorithm, and to change the parameter updates according to Algorithm 11. Note the role of the functions\n",
    "\n",
    "    self.feature_mapper.get_*_features()\n",
    "\n",
    "in providing the indices for the features obtained for $f(x^m,y^m)$ or f$(x^m,\\hat{y}^m )$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Nothing to do, ex 3.3 is about implementing the perceptron update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 3.4 - POS Tagging\n",
    "\n",
    "**Repeat Exercises 3.1â€“3.2 using the structured perceptron algorithm instead of a CRF. Report the results.**\n",
    "\n",
    "\n",
    "\n",
    "### Part 1 Run the structured perceptron with the standard feature_mapper\n",
    "Here is the code for the simple feature set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_mapper = lxmls.sequences.id_feature.IDFeatures(train_seq)\n",
    "feature_mapper.build_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxmls.sequences.structured_perceptron as spc\n",
    "\n",
    "sp = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper)\n",
    "sp.num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.656806\n",
      "Epoch: 1 Accuracy: 0.820898\n",
      "Epoch: 2 Accuracy: 0.879176\n",
      "Epoch: 3 Accuracy: 0.907432\n",
      "Epoch: 4 Accuracy: 0.925239\n",
      "Epoch: 5 Accuracy: 0.939956\n",
      "Epoch: 6 Accuracy: 0.946284\n",
      "Epoch: 7 Accuracy: 0.953790\n",
      "Epoch: 8 Accuracy: 0.958499\n",
      "Epoch: 9 Accuracy: 0.955114\n",
      "Epoch: 10 Accuracy: 0.959235\n",
      "Epoch: 11 Accuracy: 0.968065\n",
      "Epoch: 12 Accuracy: 0.968212\n",
      "Epoch: 13 Accuracy: 0.966740\n",
      "Epoch: 14 Accuracy: 0.971302\n",
      "Epoch: 15 Accuracy: 0.968653\n",
      "Epoch: 16 Accuracy: 0.970419\n",
      "Epoch: 17 Accuracy: 0.971891\n",
      "Epoch: 18 Accuracy: 0.971744\n",
      "Epoch: 19 Accuracy: 0.973510\n"
     ]
    }
   ],
   "source": [
    "sp.train_supervised(train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### The execution of the previous cell should print\n",
    "    Epoch: 0 Accuracy: 0.656806\n",
    "    Epoch: 1 Accuracy: 0.820898\n",
    "    Epoch: 2 Accuracy: 0.879176\n",
    "    Epoch: 3 Accuracy: 0.907432\n",
    "    Epoch: 4 Accuracy: 0.925239\n",
    "    Epoch: 5 Accuracy: 0.939956\n",
    "    Epoch: 6 Accuracy: 0.946284\n",
    "    Epoch: 7 Accuracy: 0.953790\n",
    "    Epoch: 8 Accuracy: 0.958499\n",
    "    Epoch: 9 Accuracy: 0.955114\n",
    "    Epoch: 10 Accuracy: 0.959235\n",
    "    Epoch: 11 Accuracy: 0.968065\n",
    "    Epoch: 12 Accuracy: 0.968212\n",
    "    Epoch: 13 Accuracy: 0.966740\n",
    "    Epoch: 14 Accuracy: 0.971302\n",
    "    Epoch: 15 Accuracy: 0.968653\n",
    "    Epoch: 16 Accuracy: 0.970419\n",
    "    Epoch: 17 Accuracy: 0.971891\n",
    "    Epoch: 18 Accuracy: 0.971744\n",
    "    Epoch: 19 Accuracy: 0.973510"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP -  Accuracy Train: 0.984 Dev: 0.835 Test: 0.840\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for the various sequences using the trained model.\n",
    "pred_train = sp.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = sp.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = sp.viterbi_decode_corpus(test_seq)\n",
    "\n",
    "# Evaluate and print accuracies\n",
    "eval_train = sp.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = sp.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = sp.evaluate_corpus(test_seq, pred_test)\n",
    "print \"SP -  Accuracy Train: %.3f Dev: %.3f Test: %.3f\"%(eval_train,eval_dev, eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The execution of the previous cell should print\n",
    "\n",
    "    SP -  Accuracy Train: 0.984 Dev: 0.835 Test: 0.840\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Run the structured perceptron with the standard feature_mapper_ext\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build features\n",
    "# import lxmls.sequences.extended_feature as exfc\n",
    "feature_mapper_ext = lxmls.sequences.extended_feature .ExtendedFeatures(train_seq)\n",
    "feature_mapper_ext.build_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxmls.sequences.structured_perceptron as spc\n",
    "\n",
    "sp_ext = spc.StructuredPerceptron(corpus.word_dict, corpus.tag_dict, feature_mapper_ext)\n",
    "sp_ext.num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Accuracy: 0.764386\n",
      "Epoch: 1 Accuracy: 0.872701\n",
      "Epoch: 2 Accuracy: 0.903458\n",
      "Epoch: 3 Accuracy: 0.927594\n",
      "Epoch: 4 Accuracy: 0.938484\n",
      "Epoch: 5 Accuracy: 0.951141\n",
      "Epoch: 6 Accuracy: 0.949816\n",
      "Epoch: 7 Accuracy: 0.959529\n",
      "Epoch: 8 Accuracy: 0.957616\n",
      "Epoch: 9 Accuracy: 0.962325\n",
      "Epoch: 10 Accuracy: 0.961148\n",
      "Epoch: 11 Accuracy: 0.970567\n",
      "Epoch: 12 Accuracy: 0.968212\n",
      "Epoch: 13 Accuracy: 0.973216\n",
      "Epoch: 14 Accuracy: 0.974393\n",
      "Epoch: 15 Accuracy: 0.973951\n",
      "Epoch: 16 Accuracy: 0.976600\n",
      "Epoch: 17 Accuracy: 0.977483\n",
      "Epoch: 18 Accuracy: 0.974834\n",
      "Epoch: 19 Accuracy: 0.977042\n"
     ]
    }
   ],
   "source": [
    "sp_ext.train_supervised(train_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The execution of the previous cell should print\n",
    "    Epoch: 0 Accuracy: 0.764386\n",
    "    Epoch: 1 Accuracy: 0.872701\n",
    "    Epoch: 2 Accuracy: 0.903458\n",
    "    Epoch: 3 Accuracy: 0.927594\n",
    "    Epoch: 4 Accuracy: 0.938484\n",
    "    Epoch: 5 Accuracy: 0.951141\n",
    "    Epoch: 6 Accuracy: 0.949816\n",
    "    Epoch: 7 Accuracy: 0.959529\n",
    "    Epoch: 8 Accuracy: 0.957616\n",
    "    Epoch: 9 Accuracy: 0.962325\n",
    "    Epoch: 10 Accuracy: 0.961148\n",
    "    Epoch: 11 Accuracy: 0.970567\n",
    "    Epoch: 12 Accuracy: 0.968212\n",
    "    Epoch: 13 Accuracy: 0.973216\n",
    "    Epoch: 14 Accuracy: 0.974393\n",
    "    Epoch: 15 Accuracy: 0.973951\n",
    "    Epoch: 16 Accuracy: 0.976600\n",
    "    Epoch: 17 Accuracy: 0.977483\n",
    "    Epoch: 18 Accuracy: 0.974834\n",
    "    Epoch: 19 Accuracy: 0.977042\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP_ext -  Accuracy Train: 0.984 Dev: 0.888 Test: 0.890\n"
     ]
    }
   ],
   "source": [
    "# Make predictions for the various sequences using the trained model.\n",
    "pred_train = sp_ext.viterbi_decode_corpus(train_seq)\n",
    "pred_dev = sp_ext.viterbi_decode_corpus(dev_seq)\n",
    "pred_test = sp_ext.viterbi_decode_corpus(test_seq)\n",
    "\n",
    "# Evaluate and print accuracies\n",
    "eval_train = sp_ext.evaluate_corpus(train_seq, pred_train)\n",
    "eval_dev = sp_ext.evaluate_corpus(dev_seq, pred_dev)\n",
    "eval_test = sp_ext.evaluate_corpus(test_seq, pred_test)\n",
    "print \"SP_ext -  Accuracy Train: %.3f Dev: %.3f Test: %.3f\"%(eval_train,eval_dev, eval_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The execution of the previous cell should print\n",
    "    SP_ext - Accuracy Train: 0.984 Dev: 0.888 Test: 0.890\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Summary\n",
    "\n",
    "\n",
    "| Model   | Train acc | Dev acc | Test acc |\n",
    "| --------| --------- | ------- |--------- |\n",
    "| crf     |  0.949    | 0.846   |   0.858  |\n",
    "| crf_ext |  0.984    | 0.899   |   0.894  |\n",
    "| sp      |  0.984    | 0.835   |   0.840  |\n",
    "| sp_ext  |  0.984    | 0.888   |   0.890  |\n",
    "\n",
    "\n",
    "\n",
    "CRF -  Accuracy Train: 0.949 Dev: 0.846 Test: 0.858\n",
    "\n",
    "CRF_ext -  Accuracy Train: 0.984 Dev: 0.899 Test: 0.894\n",
    "\n",
    "SP -  Accuracy Train: 0.984 Dev: 0.835 Test: 0.840\n",
    "\n",
    "SP_ext Train: 0.984 Dev: 0.835 Test: 0.840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
